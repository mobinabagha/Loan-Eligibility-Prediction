{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88466021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"null max:,{loan_df_dropnull.isnull().sum(axis=1).max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51570e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_df_dropnull = loan_df[loan_df.isnull().sum(axis=1) < loan_df.isnull().sum(axis=1).max()]\n",
    "# loan_df_dropnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29579dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer  # Required for IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081db65",
   "metadata": {},
   "source": [
    "# ❌ Wrong pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"binary_cols\" , OrdinalEncoder()),\n",
    "        (\"ordinal_cols\" ,OrdinalEncoder(categories=[['0', '1', '2', '3+']])),\n",
    "        (\"nominal_cols\" ,OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "impute_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"binary_cols\" ,IterativeImputer()),\n",
    "        (\"ordinal_cols\" ,IterativeImputer()),\n",
    "        (\"nominal_cols\" ,IterativeImputer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_scale_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"Scaler\",StandardScaler())\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd96551",
   "metadata": {},
   "source": [
    "# ❌ Wrong use of columntransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f361db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "StandardScaler_numerical = ColumnTransformer(\n",
    "    transformers=[(\"scale\",StandardScaler(),numerical_cols)]\n",
    ")\n",
    "\n",
    "MinMaxScaler_numerical = ColumnTransformer(\n",
    "    transformers=[(\"scale\",MinMaxScaler(),numerical_cols)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"col_trans\" ,col_trans),\n",
    "        (\"scale\",StandardScaler_numerical),\n",
    "        (\"model\", log_reg_clf)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778500c3",
   "metadata": {},
   "source": [
    "col_trans is presumably a ColumnTransformer that already handles encoding (binary, ordinal, nominal). ✅\n",
    "\n",
    "Then you’re doing another StandardScaler step (StandardScaler_numerical) which itself is a ColumnTransformer.\n",
    "\n",
    "Here’s the issue:\n",
    "\n",
    "After col_trans, the output is a NumPy array, because ColumnTransformer returns an array by default.\n",
    "\n",
    "StandardScaler_numerical is a ColumnTransformer that tries to select columns by names (numerical_cols), but the array no longer has column names → ValueError."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
